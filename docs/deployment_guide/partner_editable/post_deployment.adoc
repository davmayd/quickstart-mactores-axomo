// Include any postdeployment steps here, such as steps necessary to test that the deployment was successful. If there are no postdeployment steps, leave this file empty.

== Postdeployment steps

Use the URLs displayed in the *Outputs* tab for the stack to view the resources that were created.

[#postdeploy1]
.Outputs tab
image::../docs/deployment_guide/images/image3.jpeg[PostDeploy]

=== Test the deployment

Once the stack is successfully deployed, you will be taken to the Axomo portal. To test the deployment:

* Log in to the portal, and provide your credentials for the IBM Spectrum LSF RTM database, with the host name or server IP address, admin user name, and admin password.

[#postdeploy2]
.Logging in
image::../docs/deployment_guide/images/image4.png[PostDeploy]

* Once the connection is successful, you will see the word “Connected” and *Migrate the data* will be enabled.

[#postdeploy2]
.Successfully connected
image::../docs/deployment_guide/images/image5.png[PostDeploy]

Data migration takes about 4 to 32 hours depending upon the size of the dataset. Once the migration is successful, you can see the outcomes in the form of a dashboard, which includes the following:

* *Usage analysis*. Analysis of current usage of hardware, licenses, and queues.
* *Queue analysis*. This analysis provides free/busy queues and indicates ways to optimize wait time and run time.
* *Heatmap*. The heatmap provides the analysis of queue usage with respect to time, indicating the problem areas of queue usage.

*Recommendations*. These contain to do’s based on the analysis, which can include advice on optimizing queues, hardware resources, or software resources.

=== Best practices for using Axomo on AWS

If you have sensitive data, you can enable server-side data encryption in Amazon S3. Use AWS CloudTrail to record actions taken by a user, role, or an AWS service in all services. In Amazon S3, you can encrypt objects by using server-side encryption with keys that are either managed by Amazon S3 or by AWS Key Management Service (AWS KMS).

AWS Glue supports data encryption at rest. You can configure extract, transform, and load (ETL) jobs and development endpoints to use AWS KMS keys for writing encrypted data at rest. You can also encrypt the metadata stored in the AWS Glue Data Catalog using keys that you manage with AWS KMS.

Additionally, you can use AWS KMS keys to encrypt job bookmarks and the logs generated by crawlers and ETL jobs. AWS provides Secure Sockets Layer (SSL) encryption for data in motion. You can configure encryption settings for crawlers, ETL jobs, and development endpoints using security configurations in AWS Glue. You can enable AWS Glue Data Catalog encryption via the settings for the Data Catalog.

=== Security

All of the services are deployed in a private subnet, and the portal can only be accessed through Site-to-Site VPN. This deployment uses all the serverless services with best practices implemented for each service including

* https://docs.aws.amazon.com/glue/latest/dg/security.html[AWS Glue]
* https://docs.aws.amazon.com/athena/latest/ug/security.html[Amazon Athena]
* https://docs.aws.amazon.com/sagemaker/latest/dg/security.html[Amazon SageMaker]
* https://docs.aws.amazon.com/lambda/latest/dg/lambda-security.html[AWS Lambda]
